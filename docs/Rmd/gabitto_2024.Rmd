
---
title: "Tutorial for analyzing Seurat datasets with Pasta"
author: "Jérôme Salignon"
date: "`r Sys.Date()`"
output:
  md_document:
    variant: gfm
    toc: true
---

# Introduction

# Introduction

This tutorial demonstrates an analysis using the **Pasta** package on the dataset **L5 ET - MTG** from Gabitto, *Nature Neuroscience*, 2024.  
The study, *"Integrated multimodal cell atlas of Alzheimer’s disease"*, is available at [CellxGene](https://cellxgene.cziscience.com/collections/1ca90a2d-2943-483d-b678-b809bf464c30) and [Nature Neuroscience](https://doi.org/10.1038/s41593-024-01774-5). In particular, the dataset "L5 ET - MTG: Seattle Alzheimer's Disease Atlas (SEA-AD)" of 2,590 cells was downloaded from CellxGene. These cells corresponds to Layer 5 extratelencephalic cortical neurons in the middle temporal gyrus. 


# Data Acquisition, Age-Prediction, and Processing

In this section, we load the example Seurat object, process the metadata, filter cell types, and create pseudobulk samples for age prediction.

## Loading Libraries and Dataset

Loading libraries.
```{r setup, include=FALSE}
library(pasta)
library(jsutil)
library(magrittr)
library(data.table)
library(ggplot2)

# Create output directory if needed
if (!dir.exists("../output")) {
  dir.create("../output")
}
```

Downloading data
```{r download-data, message=FALSE, warning=FALSE}
file_Gabitto2024 = '../output/seu_gabitto_2024.rds'
if(!file.exists(file_Gabitto2024)){
  download.file('https://datasets.cellxgene.cziscience.com/9d53f7bb-dc23-4c05-b2a6-4afa9a6e3be0.rds', destfile = '../output/seu_gabitto_2024.rds')
}
```

Filtering data to keep only cells from healthy donors with known age and made with the 10X 3' method.
```{r filtering-data, message=FALSE, warning=FALSE}
file_Gabitto2024_filtered = '../output/seu_gabitto_2024_filtered.rds'
if(!file.exists(file_Gabitto2024_filtered)){
  seu = readRDS(file_Gabitto2024)
  object.size(seu) # 572885136 bytes
  # Removing samples: removing 930 dementia patients
  seu = seu[, seu$disease == 'normal'] %T>% pncol
  object.size(seu) # 363434608 bytes
  # Removing 175 10x multiome samples,
  seu = seu[, seu$assay == '10x 3\' v3'] %T>% pncol
  object.size(seu) # 326000136 bytes
  # Removing 63 samples from donors or unknown age,
  seu = seu[, seu$development_stage != 'adult stage'] %T>% pncol
  object.size(seu) # 313914208 bytes
  saveRDS(seu, file_Gabitto2024_filtered)
}
```


## Processing the Metadata

We adjust the metadata to extract age information and cell type annotations.

```{r process-metadata, message=FALSE, warning=FALSE}
seu = readRDS(file_Gabitto2024_filtered)
# Process the metadata: remove extra characters from development_stage and convert cell type to character.
seu$age  <- seu$development_stage %>% gsub("-year.*", "", .) %>% 
  gsub("-", " ", .) %>% gsub('80 year old and over stage', '85', .)
seu$type <- seu$cell_type %>% as.character
```

Distribution of ages
```{r distrib-ages, message=FALSE, warning=FALSE}
seu@meta.data$age %>% table
```

Distribution of cell types
```{r distrib-cell_type, message=FALSE, warning=FALSE}
seu@meta.data$cell_type %>% table
```

Preview cell type filtering (dry-run)
```{r Preview-filter, message=FALSE, warning=FALSE}
seu %>% filter_cell_types_in_seu_object(n_cell_min = 500, dry_run = TRUE, verbose = TRUE)
```
=> This function allows to remove cell types without a given number of cells. 


## Filtering and Creating Pseudobulk Samples

We filter the Seurat object to retain only cell types with at least 500 cells, and then create pseudobulk samples for age prediction.

```{r filter-pseudobulk, message=FALSE, warning=FALSE}
# Filter the Seurat object to keep only cell types with at least 500 cells
seu %<>% filter_cell_types_in_seu_object %T>% pdim

# Predict age using a single chunk sizes
# dt_age_pred <- making_pseudobulks_and_predict_age(seu, chunk_size = 1000)
# => faster if needed

# Predict age using multiple pseudobulk chunk sizes
v_chunk_sizes <- 2^(0:10)
dt_age_pred <- predicting_age_multiple_chunks(seu, v_chunk_sizes, verbose = T)
```


# Results

In this section, we compute correlations between the true age and predicted age scores and visualize the results.

## Correlation Analysis

```{r compute-correlations, message=FALSE, warning=FALSE}
# Compute correlations by chunk size for different modeling strategies
dt_cor <- dt_age_pred[, .( 
  n_pseudobulks = .N,
  REG = cor(age, REG),
  PASTA = cor(age, PASTA),
  TC46 = cor(age, CT46)), by = chunk_size]
print(dt_cor)
```


```{r reshape-correlations, message=FALSE, warning=FALSE}
# Reshape the data into long format for plotting
cur_dt1 <- melt(dt_cor[, c(1, 3:5)], id.vars = "chunk_size", 
                variable.name = "Modeling_strategy", 
                value.name = "PCC")

# Optionally, add or adjust factor levels for the modeling strategies
model_levels <- c('REG', 'TC46', 'PASTA')
cur_dt1$Modeling_strategy <- factor(cur_dt1$Modeling_strategy, levels = model_levels)
# print(cur_dt1)
```

## Visualization

We now plot the Pearson correlation coefficients (PCC) for the different modeling strategies across chunk sizes.

```{r plot-correlations, message=FALSE, warning=FALSE}
# Plot PCC vs. log2(chunk_size) for different modeling strategies
p1 <- ggplot(cur_dt1, aes(x = log2(chunk_size), y = PCC, colour = Modeling_strategy)) +
  geom_point(size = 2) +
  geom_line() +
  scale_colour_manual(values = c('PASTA' = 'red2', 'REG' = 'dodgerblue', 'TC46' = 'forestgreen')) +
  ggtitle("Correlation between True Age and Predicted Age Scores") +
  xlab("log2(Chunk Size)") +
  ylab("Pearson Correlation Coefficient (PCC)") +
  theme_minimal()

print(p1)
```
